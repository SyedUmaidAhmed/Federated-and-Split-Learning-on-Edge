{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Ensemble 1D-CNN Client Side\n",
    "This code is the server part of ECG ensemble 1D-CNN model for **multi** client and a server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = 3 # number of clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import socket\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../../models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "torch.manual_seed(777)\n",
    "if device ==\"cuda:0\":\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_order(start from 0): 0\n"
     ]
    }
   ],
   "source": [
    "client_order = int(input(\"client_order(start from 0): \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_traindata = 13244 // users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ECG dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        if train:\n",
    "            # total: 13244\n",
    "            with h5py.File(os.path.join(root_path, 'ecg_data', 'train_ecg.hdf5'), 'r') as hdf:\n",
    "                self.x = hdf['x_train'][num_traindata * client_order : num_traindata * (client_order + 1)]\n",
    "                self.y = hdf['y_train'][num_traindata * client_order : num_traindata * (client_order + 1)]\n",
    "\n",
    "        else:\n",
    "            with h5py.File(os.path.join(root_path, 'ecg_data', 'test_ecg.hdf5'), 'r') as hdf:\n",
    "                self.x = hdf['x_test'][:]\n",
    "                self.y = hdf['y_test'][:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x[idx], dtype=torch.float), torch.tensor(self.y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make train and test dataset batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ECG(train=True)\n",
    "test_dataset = ECG(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 130])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = next(iter(train_loader))\n",
    "print(x_train.size())\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(train_loader)\n",
    "print(total_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ECG client model\n",
    "Client side has only **2 convolutional layers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ecgclient(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Ecgclient, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ecgclient(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (relu1): LeakyReLU(negative_slope=0.01)\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu2): LeakyReLU(negative_slope=0.01)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ecg_client = Ecgclient().to(device)\n",
    "print(ecg_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# print('ECG 1D CNN clients')\n",
    "# summary(ecg_client, (1, 130))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set other hyperparameters in the model\n",
    "Hyperparameters here should be same with the server side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20  # default\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "optimizer = Adam(ecg_client.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socket initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required socket functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    msg = struct.pack('>I', len(msg)) + msg\n",
    "    sock.sendall(msg)\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    msg =  recvall(sock, msglen)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set host address and port number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP address: 192.168.83.1\n"
     ]
    }
   ],
   "source": [
    "host = input(\"IP address: \")\n",
    "port = 10080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET TIMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timmer start!\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()    # store start time\n",
    "print(\"timmer start!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the client socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = socket.socket()\n",
    "s.connect((host, port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = recv_msg(s)   # get epoch\n",
    "epochs = msg['epochs']\n",
    "users = msg['users']\n",
    "msg = total_batch\n",
    "send_msg(s, msg)   # send total_batch of train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1_0:   0%|                                                            | 0/138 [00:00<?, ?it/s]C:\\Users\\rlaal\\anaconda3\\envs\\py36\\lib\\site-packages\\torch\\storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "Epoch 1_0: 100%|██████████████████████████████████████████████████| 138/138 [00:07<00:00, 18.04it/s]\n",
      "Epoch 1_1: 100%|██████████████████████████████████████████████████| 138/138 [00:06<00:00, 22.45it/s]\n",
      "Epoch 1_2: 100%|██████████████████████████████████████████████████| 138/138 [00:07<00:00, 18.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    for u in range(users):\n",
    "        client_weights = recv_msg(s)\n",
    "        ecg_client.load_state_dict(client_weights)\n",
    "        ecg_client.eval()\n",
    "        for i, data in enumerate(tqdm(train_loader, ncols=100, desc='Epoch '+str(e+1)+ '_' +str(u))):\n",
    "            x, label = data\n",
    "            x = x.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = ecg_client(x)\n",
    "            client_output = output.clone().detach().requires_grad_(True)\n",
    "            msg = {\n",
    "                'client_output': client_output,\n",
    "                'label': label\n",
    "            }\n",
    "            send_msg(s, msg)\n",
    "            client_grad = recv_msg(s)\n",
    "            output.backward(client_grad)\n",
    "            optimizer.step()\n",
    "        msg = copy.deepcopy(ecg_client.state_dict())\n",
    "        send_msg(s, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkingTime of  cpu : 31.274245500564575 sec\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()  #store end time\n",
    "print(\"WorkingTime of \",device ,\": {} sec\".format(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
