{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Ensemble 1D-CNN Server Side\n",
    "This code is the server part of ECG ensemble 1D-CNN model for **multi** client and a server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 400\n",
    "users = 3 # number of users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "import struct\n",
    "import pickle\n",
    "from threading import Thread\n",
    "from threading import Lock\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device ==\"cuda:0\":\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../../models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        if train:\n",
    "            with h5py.File(os.path.join(root_path, 'ecg_data', 'train_ecg.hdf5'), 'r') as hdf:\n",
    "                self.x = hdf['x_train'][:]\n",
    "                self.y = hdf['y_train'][:]\n",
    "        else:\n",
    "            with h5py.File(os.path.join(root_path, 'ecg_data', 'test_ecg.hdf5'), 'r') as hdf:\n",
    "                self.x = hdf['x_test'][:]\n",
    "                self.y = hdf['y_test'][:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x[idx], dtype=torch.float), torch.tensor(self.y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make train and test dataset batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ECG(train=True)\n",
    "test_dataset = ECG(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_models = [0] * users\n",
    "original_models = [0] * users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ECG server model\n",
    "Server side has **1 convolutional layer** and **2 fully connected layers**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EcgServer1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EcgServer1, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "#         self.relu1 = nn.LeakyReLU()\n",
    "#         self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "#         self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "#         self.relu2 = nn.LeakyReLU()\n",
    "        self.conv3 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.conv4 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.pool4 = nn.MaxPool1d(2)  # 32 x 16\n",
    "        self.linear5 = nn.Linear(32 * 16, 128)\n",
    "        self.relu5 = nn.LeakyReLU()\n",
    "        self.linear6 = nn.Linear(128, 5)\n",
    "        self.softmax6 = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "        x = x.view(-1, 32 * 16)\n",
    "        x = self.linear5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.linear6(x)\n",
    "        x = self.softmax6(x)\n",
    "        return x   \n",
    "    \n",
    "class Ecgnet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Ecgnet1, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.conv3 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.conv4 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.pool4 = nn.MaxPool1d(2)  # 32 x 16\n",
    "        self.linear5 = nn.Linear(32 * 16, 128)\n",
    "        self.relu5 = nn.LeakyReLU()\n",
    "        self.linear6 = nn.Linear(128, 5)\n",
    "        self.softmax6 = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "        x = x.view(-1, 32 * 16)\n",
    "        x = self.linear5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.linear6(x)\n",
    "        x = self.softmax6(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EcgServer1(\n",
      "  (conv3): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu3): LeakyReLU(negative_slope=0.01)\n",
      "  (conv4): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu4): LeakyReLU(negative_slope=0.01)\n",
      "  (pool4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear5): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (relu5): LeakyReLU(negative_slope=0.01)\n",
      "  (linear6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (softmax6): Softmax(dim=1)\n",
      ")\n",
      "Ecgnet1(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (relu1): LeakyReLU(negative_slope=0.01)\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu2): LeakyReLU(negative_slope=0.01)\n",
      "  (conv3): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu3): LeakyReLU(negative_slope=0.01)\n",
      "  (conv4): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu4): LeakyReLU(negative_slope=0.01)\n",
      "  (pool4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear5): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (relu5): LeakyReLU(negative_slope=0.01)\n",
      "  (linear6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (softmax6): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "server_models[0] = EcgServer1().to(device)\n",
    "print(server_models[0])\n",
    "\n",
    "original_models[0] = Ecgnet1().to(device)\n",
    "print(original_models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# print('ECG 1D CNN server')\n",
    "# summary(server_models[0], (16, 65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EcgServer2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EcgServer2, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "#         self.relu1 = nn.LeakyReLU()\n",
    "#         self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "#         self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "#         self.relu2 = nn.LeakyReLU()\n",
    "        self.conv3 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.conv4 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.conv5 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu5 = nn.LeakyReLU()\n",
    "        self.pool5 = nn.MaxPool1d(2)  # 32 x 16\n",
    "        self.linear6 = nn.Linear(32 * 16, 128)\n",
    "        self.relu6 = nn.LeakyReLU()\n",
    "        self.linear7 = nn.Linear(128, 5)\n",
    "        self.softmax7 = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.pool5(x)\n",
    "        x = x.view(-1, 32 * 16)\n",
    "        x = self.linear6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.linear7(x)\n",
    "        x = self.softmax7(x)\n",
    "        return x   \n",
    "    \n",
    "class Ecgnet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Ecgnet2, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.conv3 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.conv4 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.conv5 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu5 = nn.LeakyReLU()\n",
    "        self.pool5 = nn.MaxPool1d(2)  # 32 x 16\n",
    "        self.linear6 = nn.Linear(32 * 16, 128)\n",
    "        self.relu6 = nn.LeakyReLU()\n",
    "        self.linear7 = nn.Linear(128, 5)\n",
    "        self.softmax7 = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.pool5(x)\n",
    "        x = x.view(-1, 32 * 16)\n",
    "        x = self.linear6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.linear7(x)\n",
    "        x = self.softmax7(x)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EcgServer2(\n",
      "  (conv3): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu3): LeakyReLU(negative_slope=0.01)\n",
      "  (conv4): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu4): LeakyReLU(negative_slope=0.01)\n",
      "  (conv5): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu5): LeakyReLU(negative_slope=0.01)\n",
      "  (pool5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear6): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (relu6): LeakyReLU(negative_slope=0.01)\n",
      "  (linear7): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (softmax7): Softmax(dim=1)\n",
      ")\n",
      "Ecgnet2(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (relu1): LeakyReLU(negative_slope=0.01)\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu2): LeakyReLU(negative_slope=0.01)\n",
      "  (conv3): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu3): LeakyReLU(negative_slope=0.01)\n",
      "  (conv4): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu4): LeakyReLU(negative_slope=0.01)\n",
      "  (conv5): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu5): LeakyReLU(negative_slope=0.01)\n",
      "  (pool5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear6): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (relu6): LeakyReLU(negative_slope=0.01)\n",
      "  (linear7): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (softmax7): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "server_models[1] = EcgServer2().to(device)\n",
    "print(server_models[1])\n",
    "\n",
    "original_models[1] = Ecgnet2().to(device)\n",
    "print(original_models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# print('ECG 1D CNN server')\n",
    "# summary(server_models[1], (16, 65))   # 16, 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EcgServer3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EcgServer3, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "#         self.relu1 = nn.LeakyReLU()\n",
    "#         self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "#         self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "#         self.relu2 = nn.LeakyReLU()\n",
    "        self.conv3 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.conv4 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.conv5 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu5 = nn.LeakyReLU()\n",
    "        self.conv6 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu6 = nn.LeakyReLU()\n",
    "        self.pool6 = nn.MaxPool1d(2)  # 32 x 16\n",
    "        self.linear7 = nn.Linear(32 * 16, 128)\n",
    "        self.relu7 = nn.LeakyReLU()\n",
    "        self.linear8 = nn.Linear(128, 5)\n",
    "        self.softmax8 = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.pool6(x)\n",
    "        x = x.view(-1, 32 * 16)\n",
    "        x = self.linear7(x)\n",
    "        x = self.relu7(x)\n",
    "        x = self.linear8(x)\n",
    "        x = self.softmax8(x)\n",
    "        return x        \n",
    "    \n",
    "class Ecgnet3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Ecgnet3, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.conv3 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.conv4 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.conv5 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu5 = nn.LeakyReLU()\n",
    "        self.conv6 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu6 = nn.LeakyReLU()\n",
    "        self.pool6 = nn.MaxPool1d(2)  # 32 x 16\n",
    "        self.linear7 = nn.Linear(32 * 16, 128)\n",
    "        self.relu7 = nn.LeakyReLU()\n",
    "        self.linear8 = nn.Linear(128, 5)\n",
    "        self.softmax8 = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.pool6(x)\n",
    "        x = x.view(-1, 32 * 16)\n",
    "        x = self.linear7(x)\n",
    "        x = self.relu7(x)\n",
    "        x = self.linear8(x)\n",
    "        x = self.softmax8(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EcgServer3(\n",
      "  (conv3): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu3): LeakyReLU(negative_slope=0.01)\n",
      "  (conv4): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu4): LeakyReLU(negative_slope=0.01)\n",
      "  (conv5): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu5): LeakyReLU(negative_slope=0.01)\n",
      "  (conv6): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu6): LeakyReLU(negative_slope=0.01)\n",
      "  (pool6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear7): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (relu7): LeakyReLU(negative_slope=0.01)\n",
      "  (linear8): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (softmax8): Softmax(dim=1)\n",
      ")\n",
      "Ecgnet3(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (relu1): LeakyReLU(negative_slope=0.01)\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu2): LeakyReLU(negative_slope=0.01)\n",
      "  (conv3): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu3): LeakyReLU(negative_slope=0.01)\n",
      "  (conv4): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu4): LeakyReLU(negative_slope=0.01)\n",
      "  (conv5): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu5): LeakyReLU(negative_slope=0.01)\n",
      "  (conv6): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu6): LeakyReLU(negative_slope=0.01)\n",
      "  (pool6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear7): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (relu7): LeakyReLU(negative_slope=0.01)\n",
      "  (linear8): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (softmax8): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "server_models[2] = EcgServer3().to(device)\n",
    "print(server_models[2])\n",
    "\n",
    "original_models[2] = Ecgnet3().to(device)\n",
    "print(original_models[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ecgclient(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Ecgclient, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ecgclient(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (relu1): LeakyReLU(negative_slope=0.01)\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu2): LeakyReLU(negative_slope=0.01)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ecg_client = Ecgclient().to(device)\n",
    "print(ecg_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# print('ECG 1D CNN client')\n",
    "# summary(ecg_client, (1, 130))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set other hyperparameters in the model\n",
    "Hyperparameters here should be same with the client side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "optimizer_server_list = []\n",
    "for model in server_models:\n",
    "    optimizer_server_list.append(Adam(model.parameters(), lr=lr))\n",
    "\n",
    "clientsoclist = [0] * users\n",
    "val_acc = [[] for i in range(users)]\n",
    "train_acc = [[] for i in range(users)]\n",
    "\n",
    "client_weights = []\n",
    "weight_count = 0\n",
    "weights = copy.deepcopy(ecg_client.state_dict())\n",
    "for _ in range(users):\n",
    "    client_weights.append(weights)\n",
    "\n",
    "start_time = 0\n",
    "lock = Lock()\n",
    "    \n",
    "###########################################################################\n",
    "\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sendsize_list = []\n",
    "total_receivesize_list = []\n",
    "\n",
    "client_sendsize_list = [[] for i in range(users)]\n",
    "client_receivesize_list = [[] for i in range(users)]\n",
    "\n",
    "train_sendsize_list = [] \n",
    "train_receivesize_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socket initialization\n",
    "### Set host address and port number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required socket functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    l_send = len(msg)\n",
    "    msg = struct.pack('>I', l_send) + msg\n",
    "    sock.sendall(msg)\n",
    "    return l_send\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    msg =  recvall(sock, msglen)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg, msglen\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_thread(func, num_user):\n",
    "    global clientsoclist\n",
    "    global start_time\n",
    "    thrs = []\n",
    "    for i in range(num_user):\n",
    "        conn, addr = s.accept()\n",
    "        print('Conntected with', addr)\n",
    "        # append client socket on list\n",
    "        clientsoclist[i] = conn\n",
    "        args = (i, num_user, conn)\n",
    "        thread = Thread(target=func, args=args)\n",
    "        thrs.append(thread)\n",
    "        thread.start()\n",
    "    print(\"timmer start!\")\n",
    "    start_time = time.time()    # store start time\n",
    "    for thread in thrs:\n",
    "        thread.join()\n",
    "    end_time = time.time()  # store end time\n",
    "    print(\"TrainingTime: {} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receive client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive(userid, num_users, conn): #thread for receive clients\n",
    "    global weight_count\n",
    "    \n",
    "\n",
    "\n",
    "    msg = {\n",
    "        'epochs': epochs,\n",
    "        'users': users\n",
    "    }\n",
    "\n",
    "    datasize = send_msg(conn, msg)    #send epoch\n",
    "    total_sendsize_list.append(datasize)\n",
    "    client_sendsize_list[userid].append(datasize)\n",
    "\n",
    "    total_batch, datasize = recv_msg(conn)    # get total_batch of train dataset\n",
    "    total_receivesize_list.append(datasize)\n",
    "    client_receivesize_list[userid].append(datasize)\n",
    "    with lock:\n",
    "        weight_count += 1\n",
    "    \n",
    "    train(userid, total_batch, num_users, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(userid, total_batch, num_users, client_conn):\n",
    "    global client_weights\n",
    "    global weight_count\n",
    "\n",
    "    model_num = userid\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        for user in range(num_users):\n",
    "            with lock:\n",
    "                if weight_count == num_users:\n",
    "                    interval = model_num - userid\n",
    "                    for i, conn in enumerate(clientsoclist):\n",
    "                        datasize = send_msg(conn, client_weights[(i + interval) % num_users])\n",
    "                        total_sendsize_list.append(datasize)\n",
    "                        client_sendsize_list[i].append(datasize)\n",
    "                        train_sendsize_list.append(datasize)\n",
    "                        weight_count = 0\n",
    "                        \n",
    "            for i in range(total_batch):\n",
    "                optimizer_server_list[model_num].zero_grad()  # initialize all gradients to zero\n",
    "\n",
    "                msg, datasize = recv_msg(client_conn)  # receive client message from socket\n",
    "                total_receivesize_list.append(datasize)\n",
    "                client_receivesize_list[userid].append(datasize)\n",
    "                train_receivesize_list.append(datasize)\n",
    "\n",
    "                client_output_cpu = msg['client_output']  # client output tensor\n",
    "                label = msg['label']  # label\n",
    "\n",
    "                client_output = client_output_cpu.to(device)\n",
    "                label = label.clone().detach().long().to(device)\n",
    "\n",
    "                output = server_models[model_num](client_output)  # forward propagation\n",
    "                loss = criterion(output, label)  # calculates cross-entropy loss\n",
    "                loss.backward()  # backward propagation\n",
    "                msg = client_output_cpu.grad.clone().detach()\n",
    "\n",
    "                datasize = send_msg(client_conn, msg)\n",
    "                total_sendsize_list.append(datasize)\n",
    "                client_sendsize_list[userid].append(datasize)\n",
    "                train_sendsize_list.append(datasize)\n",
    "\n",
    "                optimizer_server_list[model_num].step()\n",
    "                \n",
    "            \n",
    "            weights, datasize = recv_msg(client_conn)\n",
    "            total_receivesize_list.append(datasize)\n",
    "            client_receivesize_list[userid].append(datasize)\n",
    "            train_receivesize_list.append(datasize)\n",
    "            with lock:\n",
    "                client_weights[model_num] = weights\n",
    "                weight_count += 1\n",
    "            model_num = (model_num + 1) % num_users\n",
    "        print(\"Epoch {}'s user {} is done\".format(e, userid))\n",
    "        \n",
    "        \n",
    "        ecg_client.load_state_dict(client_weights[userid])\n",
    "        ecg_client.to(device)\n",
    "\n",
    "        ecg_client_dict = ecg_client.state_dict()\n",
    "        ecg_server_dict = server_models[userid].state_dict()\n",
    "        ecg_original_dict = original_models[userid].state_dict()\n",
    "\n",
    "        ecg_original_dict.update(ecg_client_dict)\n",
    "        ecg_original_dict.update(ecg_server_dict)\n",
    "\n",
    "        original_models[userid].load_state_dict(ecg_original_dict)\n",
    "        original_models[userid].eval()\n",
    "\n",
    "        # train acc\n",
    "        with torch.no_grad():\n",
    "            corr_num = 0\n",
    "            total_num = 0\n",
    "            train_loss = 0.0\n",
    "            for j, trn in enumerate(train_loader):\n",
    "                trn_x, trn_label = trn\n",
    "                trn_x = trn_x.to(device)\n",
    "\n",
    "                trn_label = trn_label.clone().detach().long().to(device)\n",
    "\n",
    "\n",
    "                trn_output = original_models[userid](trn_x)\n",
    "                loss = criterion(trn_output, trn_label)\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                model_label = trn_output.argmax(dim=1)\n",
    "                corr = trn_label[trn_label == model_label].size(0)\n",
    "                corr_num += corr\n",
    "                total_num += trn_label.size(0)\n",
    "            train_accuracy = corr_num / total_num * 100\n",
    "            r_train_loss = train_loss / len(train_loader)\n",
    "            print(\"model {}'s train_acc: {:.2f}%, train_loss: {:.4f}\".format(userid, train_accuracy, r_train_loss))\n",
    "            train_acc[userid].append(train_accuracy)\n",
    "\n",
    "        # test acc\n",
    "        with torch.no_grad():\n",
    "            corr_num = 0\n",
    "            total_num = 0\n",
    "            val_loss = 0.0\n",
    "            for j, val in enumerate(test_loader):\n",
    "                val_x, val_label = val\n",
    "                val_x = val_x.to(device)\n",
    "                val_label = val_label.to(device)\n",
    "\n",
    "                val_output = original_models[userid](val_x)\n",
    "                val_label = val_label.long()\n",
    "                loss = criterion(val_output, val_label)\n",
    "                val_loss += loss.item()\n",
    "                model_label = val_output.argmax(dim=1)\n",
    "                corr = val_label[val_label == model_label].size(0)\n",
    "                corr_num += corr\n",
    "                total_num += val_label.size(0)\n",
    "            test_accuracy = corr_num / total_num * 100\n",
    "            test_loss = val_loss / len(test_loader)\n",
    "            print(\"model {}'s test_acc: {:.2f}%, test_loss: {:.4f}\".format(userid, test_accuracy, test_loss))\n",
    "            val_acc[userid].append(test_accuracy)\n",
    "\n",
    "            \n",
    "            \n",
    "    print('{} is complite'.format(userid))\n",
    "            \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.83.1\n"
     ]
    }
   ],
   "source": [
    "host = socket.gethostbyname(socket.gethostname())\n",
    "port = 10080\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the server socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to connect\n"
     ]
    }
   ],
   "source": [
    "s = socket.socket()\n",
    "try:\n",
    "    s.bind((host, port))\n",
    "    print('Success to connect')\n",
    "except:\n",
    "    print('Fail to connect')\n",
    "    \n",
    "s.listen(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conntected with ('192.168.83.1', 1891)\n",
      "Conntected with ('192.168.83.1', 1894)\n",
      "Conntected with ('192.168.83.1', 1897)\n",
      "timmer start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlaal\\anaconda3\\envs\\py36\\lib\\site-packages\\torch\\storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0's user 1 is done\n",
      "Epoch 0's user 2 is done\n",
      "Epoch 0's user 0 is done\n",
      "model 1's train_acc: 74.96%, train_loss: 1.1552\n",
      "model 2's train_acc: 68.27%, train_loss: 1.2196\n",
      "model 0's train_acc: 79.61%, train_loss: 1.1105\n",
      "model 1's test_acc: 76.11%, test_loss: 1.1477\n",
      "1 is complite\n",
      "model 2's test_acc: 68.68%, test_loss: 1.2157\n",
      "2 is complite\n",
      "model 0's test_acc: 80.51%, test_loss: 1.1018\n",
      "0 is complite\n",
      "TrainingTime: 31.657214403152466 sec\n"
     ]
    }
   ],
   "source": [
    "run_thread(receive, users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(users):\n",
    "    print('train_acc list(model{})---'.format(i))\n",
    "    for acc in train_acc[i]:\n",
    "        print(acc)\n",
    "\n",
    "    print('val_acc list(model{})---'.format(i))\n",
    "    for acc in val_acc[i]:\n",
    "        print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print commmunication overheads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc list(model0)---\n",
      "79.60739901849755\n",
      "val_acc list(model0)---\n",
      "80.50585126462816\n",
      "train_acc list(model1)---\n",
      "74.95658739146847\n",
      "val_acc list(model1)---\n",
      "76.1117402793507\n",
      "train_acc list(model2)---\n",
      "68.27482068705172\n",
      "val_acc list(model2)---\n",
      "68.68252170630427\n",
      "\n",
      "\n",
      "---total_sendsize_list---\n",
      "total_sendsize size: 165815787 bytes\n",
      "number of total_send:  1254\n",
      "\n",
      "\n",
      "---total_receivesize_list---\n",
      "total receive sizes: 166380693 bytes\n",
      "number of total receive:  1254\n",
      "\n",
      "\n",
      "---client_sendsize_list(user0)---\n",
      "total client_sendsizes(user0): 55271929 bytes\n",
      "number of client_send(user0):  418\n",
      "\n",
      "\n",
      "---client_receivesize_list(user0)---\n",
      "total client_receive sizes(user0): 55460231 bytes\n",
      "number of client_send(user0):  418\n",
      "\n",
      "\n",
      "---client_sendsize_list(user1)---\n",
      "total client_sendsizes(user1): 55271929 bytes\n",
      "number of client_send(user1):  418\n",
      "\n",
      "\n",
      "---client_receivesize_list(user1)---\n",
      "total client_receive sizes(user1): 55460231 bytes\n",
      "number of client_send(user1):  418\n",
      "\n",
      "\n",
      "---client_sendsize_list(user2)---\n",
      "total client_sendsizes(user2): 55271929 bytes\n",
      "number of client_send(user2):  418\n",
      "\n",
      "\n",
      "---client_receivesize_list(user2)---\n",
      "total client_receive sizes(user2): 55460231 bytes\n",
      "number of client_send(user2):  418\n",
      "\n",
      "\n",
      "---train_sendsize_list---\n",
      "total train_sendsizes: 165815676 bytes\n",
      "number of train_send:  1251\n",
      "\n",
      "\n",
      "---train_receivesize_list---\n",
      "total train_receivesizes: 166380678 bytes\n",
      "number of train_receive:  1251\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "print('\\n')\n",
    "print('---total_sendsize_list---')\n",
    "total_size = 0\n",
    "for size in total_sendsize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total_sendsize size: {} bytes\".format(total_size))\n",
    "print(\"number of total_send: \", len(total_sendsize_list))\n",
    "print('\\n')\n",
    "\n",
    "print('---total_receivesize_list---')\n",
    "total_size = 0\n",
    "for size in total_receivesize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total receive sizes: {} bytes\".format(total_size) )\n",
    "print(\"number of total receive: \", len(total_receivesize_list) )\n",
    "print('\\n')\n",
    "\n",
    "for i in range(users):\n",
    "    print('---client_sendsize_list(user{})---'.format(i))\n",
    "    total_size = 0\n",
    "    for size in client_sendsize_list[i]:\n",
    "#         print(size)\n",
    "        total_size += size\n",
    "    print(\"total client_sendsizes(user{}): {} bytes\".format(i, total_size))\n",
    "    print(\"number of client_send(user{}): \".format(i), len(client_sendsize_list[i]))\n",
    "    print('\\n')\n",
    "\n",
    "    print('---client_receivesize_list(user{})---'.format(i))\n",
    "    total_size = 0\n",
    "    for size in client_receivesize_list[i]:\n",
    "#         print(size)\n",
    "        total_size += size\n",
    "    print(\"total client_receive sizes(user{}): {} bytes\".format(i, total_size))\n",
    "    print(\"number of client_send(user{}): \".format(i), len(client_receivesize_list[i]))\n",
    "    print('\\n')\n",
    "\n",
    "print('---train_sendsize_list---')\n",
    "total_size = 0\n",
    "for size in train_sendsize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total train_sendsizes: {} bytes\".format(total_size))\n",
    "print(\"number of train_send: \", len(train_sendsize_list) )\n",
    "print('\\n')\n",
    "\n",
    "print('---train_receivesize_list---')\n",
    "total_size = 0\n",
    "for size in train_receivesize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total train_receivesizes: {} bytes\".format(total_size))\n",
    "print(\"number of train_receive: \", len(train_receivesize_list) )\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation after trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### acc of each acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0's Accuracy of     N : 95 %\n",
      "model 0's Accuracy of     L : 97 %\n",
      "model 0's Accuracy of     R : 72 %\n",
      "model 0's Accuracy of     A :  0 %\n",
      "model 0's Accuracy of     V : 90 %\n",
      "\n",
      "\n",
      "model 1's Accuracy of     N : 93 %\n",
      "model 1's Accuracy of     L : 77 %\n",
      "model 1's Accuracy of     R : 77 %\n",
      "model 1's Accuracy of     A :  0 %\n",
      "model 1's Accuracy of     V : 87 %\n",
      "\n",
      "\n",
      "model 2's Accuracy of     N : 44 %\n",
      "model 2's Accuracy of     L : 98 %\n",
      "model 2's Accuracy of     R : 77 %\n",
      "model 2's Accuracy of     A :  0 %\n",
      "model 2's Accuracy of     V : 82 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = ['N', 'L', 'R', 'A', 'V']\n",
    "\n",
    "\n",
    "for n, model in enumerate(original_models):\n",
    "    class_correct = list(0. for i in range(5))\n",
    "    class_total = list(0. for i in range(5))\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            x, labels = data\n",
    "            x = x.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            labels = labels.long()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(5):\n",
    "        print(\"model %d's Accuracy of %5s : %2d %%\" % (n, \n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's quickly save our trained model:\n",
    "for i, model in enumerate(original_models):\n",
    "    PATH = './ecg_es_model{}.pth'.format(i)\n",
    "    torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkingTime: 57.16648530960083 sec\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()  # store end time\n",
    "print(\"WorkingTime: {} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
